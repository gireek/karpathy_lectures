{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPAqYVUhqT664d6FK3hmu1O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gireek/karpathy_lectures/blob/main/makemore_mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IXaxosV1_49a"
      },
      "outputs": [],
      "source": [
        "# why bgram not good - context only for 2 chars"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "IYbRQDddAW2x"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/karpathy/makemore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkwVxOutDFVX",
        "outputId": "52300543-09df-4f2c-c3cd-dca8cbb9238b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'makemore'...\n",
            "remote: Enumerating objects: 64, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 64 (delta 16), reused 13 (delta 13), pack-reused 47\u001b[K\n",
            "Unpacking objects: 100% (64/64), 123.34 KiB | 1.20 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "names_path = \"./makemore/names.txt\"\n",
        "words = open(names_path, 'r').read().splitlines()"
      ],
      "metadata": {
        "id": "bSpgZhUaDFzw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the vocabulary of characters and mappings to/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "print(itos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avOD_jIBEbXh",
        "outputId": "08b3f5ce-d3e7-4d0e-ab7f-24091db910ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# didt think about ...-> e (bcz all empty before was an important case too)\n",
        "\n",
        "block_size = 3\n",
        "\n",
        "def build_dataset(words):\n",
        "  X, Y = [], []\n",
        "  for w in words:\n",
        "\n",
        "    # print(w)\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      # print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
        "      context = context[1:] + [ix] # crop and append\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  return X, Y\n",
        "\n",
        "\n",
        "X, Y = build_dataset(words[:5])"
      ],
      "metadata": {
        "id": "AgA9R4GDDYQS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_dimensions = 2\n",
        "\n",
        "C = torch.randn(27, 2)\n",
        "\n",
        "C[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5m5vKWfD7he",
        "outputId": "f06b62d8-745f-4424-b061-3dd8cc118f1f"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.8770, -0.4380])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch indexing is amzaing!!!"
      ],
      "metadata": {
        "id": "PMqtifUGJS2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C[torch.tensor([5, 5, 5])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5ckecXeI4oy",
        "outputId": "5875f709-bf2d-467f-d52b-b8efae844ff5"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8770, -0.4380],\n",
              "        [-0.8770, -0.4380],\n",
              "        [-0.8770, -0.4380]])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C[X].shape, X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2wZOgHDJQ9O",
        "outputId": "4a6d8976-28a5-428c-e91b-9bbd73084659"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3, 2]), torch.Size([32, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W1 = torch.randn((6, 100))\n",
        "b1 = torch.randn(100)\n",
        "\n",
        "C[X] @ W1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "CFou64uOJXVY",
        "outputId": "b46efeff-ea4b-4f46-b6df-27924a3a1fcf"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-698be7b98b50>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (96x2 and 6x100)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[X].reshape((C[X].shape[0] , -1))"
      ],
      "metadata": {
        "id": "QpcvcAhaJ3pv"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ineefficient since creates new memory\n",
        "torch.cat(torch.unbind(C[X], 1), 1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ireW6h9KuYE",
        "outputId": "a7176fcc-ee1d-49d4-92c8-d0ebd59c5a36"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C[X].view((32,6)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q34-e966K2j1",
        "outputId": "9cf1dd1c-8c66-4eb0-afac-cc2bf8f56a85"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how its sotred internally... u can move it around using view\n",
        "# C[X].storage()"
      ],
      "metadata": {
        "id": "qTjZ02wfLKWr"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(emb @ W1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRkjceCbLSfL",
        "outputId": "b7477a89-2e04-4d10-a1e7-683a5d58579f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to add bias per row we want to add [1, num_col] or [num_col] tensor. Latter works bcz automatically converted to former\n",
        "# to add bias per col we want to add [num_rows, 1] tensor\n",
        "\n",
        "# therefore\n",
        "\n",
        "h = torch.tanh((emb @ W1) + b1)\n",
        "h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75JFLJlYPRMt",
        "outputId": "fd0e1c40-3e5e-48f0-fc0a-ff4d466706fd"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9997,  0.9997, -1.0000,  ...,  0.1906,  0.9926, -1.0000],\n",
              "        [-0.8409,  0.9995, -0.9999,  ..., -0.9064,  0.5344, -1.0000],\n",
              "        [-0.9951,  0.9967, -0.9991,  ...,  0.9905,  0.9902, -1.0000],\n",
              "        ...,\n",
              "        [-0.9972,  0.9999, -0.9999,  ...,  0.8426,  0.9722, -0.9904],\n",
              "        [ 0.9985, -0.2426,  0.9925,  ...,  0.8610, -0.7979, -0.9992],\n",
              "        [ 0.9617, -0.9551,  0.9898,  ..., -0.7819,  0.9241, -0.1132]])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W2 = torch.randn(100 , 27)\n",
        "b2 = torch.randn(27)\n",
        "\n",
        "logits = (h @ W2) + b2\n",
        "print(logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlRHauWCPjp3",
        "outputId": "b601e4ff-5e11-4bb9-f3f0-1da6939d7cdf"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 27])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = torch.softmax(logits, axis = 1)\n",
        "print(sum(output[0]))\n",
        "print(-output[torch.arange(32), Y].log().mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b79zXkJZQcmk",
        "outputId": "df1a5164-a8a6-47c1-def5-390312ffc93d"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.0000)\n",
            "tensor(16.2188)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts = logits.exp()\n",
        "prob = counts/ counts.sum(1, keepdim=True)\n",
        "print(sum(prob[0]))\n",
        "print(-prob[torch.arange(32), Y].log().mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJJ0r67SX3DT",
        "outputId": "dd22d716-ecb1-4960-9c93-a4834237572b"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.0000)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(16.2188)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output = torch.softmax(logits, axis = 1)\n",
        "# loss = -output[torch.arange(32), Y].log().mean()\n",
        "\n",
        "# can be replaced by\n",
        "\n",
        "print(F.cross_entropy(logits, Y))\n",
        "\n",
        "## why?\n",
        "## pytroch optimimzation\n",
        "## backward pass efficient\n",
        "## numerically stable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N0SJtprYbbI",
        "outputId": "7d08da4e-75d2-48d8-a745-e6dcd4c0b896"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(16.2188)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = torch.tensor([-100, 23,2,100])\n",
        "counts = logits.exp()\n",
        "probs= counts / counts.sum()\n",
        "counts, probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mc--6wrIYbZH",
        "outputId": "a8de4816-436d-47bb-e46a-39942563948a"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([3.7835e-44, 9.7448e+09, 7.3891e+00,        inf]),\n",
              " tensor([0., 0., 0., nan]))"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "make it stable as follows"
      ],
      "metadata": {
        "id": "EEihPXAFci4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits = torch.tensor([-100, 23,2,100]) - 100\n",
        "counts = logits.exp()\n",
        "probs= counts / counts.sum()\n",
        "counts, probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLslsu0Nbt_U",
        "outputId": "c8fa4828-4b1a-408d-f6a3-cffa5646e13e"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.0000e+00, 3.6251e-34, 2.7465e-43, 1.0000e+00]),\n",
              " tensor([0.0000e+00, 3.6251e-34, 2.7465e-43, 1.0000e+00]))"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NEATLY"
      ],
      "metadata": {
        "id": "VMDb-aDDYcQO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IIqKozBukOH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " X, Y = build_dataset(words)\n",
        " print(X.shape, Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk7siWtCYbWw",
        "outputId": "93d6f6bf-3856-4789-ed74-32a263e33442"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([228146, 3]) torch.Size([228146])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.cuda()\n",
        "Y = Y.cuda()"
      ],
      "metadata": {
        "id": "q12IcQwAkqjt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C = torch.randn(27, 2).cuda()\n",
        "W1 = torch.randn((6, 100)).cuda()\n",
        "b1 = torch.randn(100).cuda()\n",
        "W2 = torch.randn(100 , 27).cuda()\n",
        "b2 = torch.randn(27).cuda()\n",
        "\n",
        "params = [C, W1, b1, W2, b2]\n",
        "\n",
        "for param in params:\n",
        "  param.requires_grad = True"
      ],
      "metadata": {
        "id": "qWdLhIroiEoF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lre = torch.linspace(-3, -1, 1000)\n",
        "lrs = 10**lre"
      ],
      "metadata": {
        "id": "VuNSF6twlgSt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lrs[:10], lrs[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WafxTZZilpy6",
        "outputId": "f22b6f92-e380-47fc-a86d-1d24e3327f18"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
              "         0.0010]),\n",
              " tensor(0.1000))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1000\n",
        "\n",
        "for i in range(num_epochs):\n",
        "  emb = C[X].reshape((C[X].shape[0] , -1))\n",
        "  h = torch.tanh((emb @ W1) + b1)\n",
        "  logits = (h @ W2) + b2\n",
        "  loss = F.cross_entropy(logits, Y)\n",
        "  print(loss)\n",
        "\n",
        "  # backward\n",
        "  for param in params:\n",
        "    param.grad = None\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  lr = 0.07\n",
        "  for param in params:\n",
        "    param.data -= lr * param.grad\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdT35ABvibGR",
        "outputId": "0e44e0b1-1e29-46e7-8c3b-033ca6636dbc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.6342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.6000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5997, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5975, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5963, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5958, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5936, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5926, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5902, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5899, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5887, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5866, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5859, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5837, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5826, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5814, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5801, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5797, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5769, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5768, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5765, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5764, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5762, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5755, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5749, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5748, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5739, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5658, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5654, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5608, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5594, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5594, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.5463, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aGaEMgIMjDiL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}